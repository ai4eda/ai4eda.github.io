# <i class="fa fa-chevron-right"></i> Publications

<br>



## <i class="fa fa-chevron-right"></i> High Level Synthesis




## <i class="fa fa-chevron-right"></i> Logic Synthesis




## <i class="fa fa-chevron-right"></i> Circuit Verification




## <i class="fa fa-chevron-right"></i> Placement

<h3></h3>
<table class="table table-hover">

<tr id="tr-PLACE-DAC2019-DREAMPlace" >
<td align='right'>
1.
</td>
<td>
    DREAMPlace: Deep Learning Toolkit-Enabled GPU Acceleration for Modern VLSI Placement <br>
    <em>Yibo&nbsp;Lin, Shounak&nbsp;Dhar, Wuxi&nbsp;Li, Haoxing&nbsp;Ren, Brucek&nbsp;Khailany, and David&nbsp;Z.&nbsp;Pan</em><br>
    DAC 2019  <br>
    
</td>
</tr>

</table>



## <i class="fa fa-chevron-right"></i> Clock Tree Synthesis




## <i class="fa fa-chevron-right"></i> Routing




## <i class="fa fa-chevron-right"></i> Timing




## <i class="fa fa-chevron-right"></i> Layout Verification




## <i class="fa fa-chevron-right"></i> Mask Optimization

<h3>Lithography Modeling</h3>
<table class="table table-hover">

<tr id="tr-DAC23_Nitho" >
<td align='right'>
1.
</td>
<td>
    Physics-Informed Optical Kernel Regression Using Complex-valued Neural Fields [<a href='https://ai4eda.github.io' target='_blank'>paper</a>]  [<a href='https://ai4eda.github.io' target='_blank'>code</a>]  [<a href='https://ai4eda.github.io' target='_blank'>slides</a>]  [<a href='https://ai4eda.github.io' target='_blank'>talk</a>]  [<a href='https://ai4eda.github.io' target='_blank'>video</a>]  [<a href='https://ai4eda.github.io' target='_blank'>project</a>] <br>
    <em>Guojin&nbsp;Chen, Zehua&nbsp;Pei, Haoyu&nbsp;Yang, Yuzhe&nbsp;Ma, Bei&nbsp;Yu, and Martin&nbsp;Wong</em><br>
    DAC 2023  <br>
    
</td>
</tr>

</table>
<h3>Ilt</h3>
<table class="table table-hover">

<tr id="tr-ICCAD21_develset" >
<td align='right'>
1.
</td>
<td>
    DevelSet: Deep Neural Level Set for Instant Mask optimization 
[<a href='javascript:;'
    onclick='$("#abs_ICCAD21_develset").toggle()'>abs</a>] [<a href='https://www.cse.cuhk.edu.hk/~byu/papers/C124-ICCAD2021-DevelSet.pdf' target='_blank'>paper</a>] <br>
    <em>Guojin&nbsp;Chen, Ziyang&nbsp;Yu, Hongduo&nbsp;Liu, Yuzhe&nbsp;Ma, and Bei&nbsp;Yu</em><br>
    ICCAD 2021  <br>
    
<div id="abs_ICCAD21_develset" style="text-align: justify; display: none" markdown="1">
With the feature size continuously shrinking in advanced technology nodes, mask optimization is increasingly crucial in the conventional design flow, accompanied by an explosive growth in prohibitive computational overhead in optical proximity correction (OPC) methods. Recently, inverse lithography technique (ILT) has drawn significant attention and is becoming prevalent in emerging OPC solutions. However, ILT methods are either time-consuming or in weak performance of mask printability and manufacturability. In this paper, we present DevelSet, a GPU and deep neural network (DNN) accelerated level set OPC framework for metal layer. We first improve the conventional level set-based ILT algorithm by introducing the curvature term to reduce mask complexity and applying GPU acceleration to overcome computational bottlenecks. To further enhance printability and fast iterative convergence, we propose a novel deep neural network delicately designed with level set intrinsic principles to facilitate the joint optimization of DNN and GPU accelerated level set optimizer. Experimental results show that DevelSet framework surpasses the state-of-theart methods in printability and boost the runtime performance achieving instant level (around 1 second).
</div>

</td>
</tr>

</table>
<h3>Mask Optimization</h3>
<table class="table table-hover">

<tr id="tr-ICCAD22_AdaOPC" >
<td align='right'>
1.
</td>
<td>
    AdaOPC: A Self-Adaptive Mask Optimization Framework For Real Design Patterns <br>
    <em>Wenqian&nbsp;Zhao, Xufeng&nbsp;Yao, Ziyang&nbsp;Yu, Guojin&nbsp;Chen, Yuzhe&nbsp;Ma, Bei&nbsp;Yu, and Martin&nbsp;Wong</em><br>
    ICCAD 2022  <br>
    
</td>
</tr>


<tr id="tr-ICCAD20_damo" >
<td align='right'>
2.
</td>
<td>
    DAMO: Deep Agile Mask Optimization for Full Chip Scale 
[<a href='javascript:;'
    onclick='$("#abs_ICCAD20_damo").toggle()'>abs</a>] [<a href='https://www.cse.cuhk.edu.hk/~byu/papers/C104-ICCAD2020-DAMO.pdf' target='_blank'>paper</a>] <br>
    <em>Guojin&nbsp;Chen, Wanli&nbsp;Chen, Yuzhe&nbsp;Ma, Haoyu&nbsp;Yang, and Bei&nbsp;Yu</em><br>
    ICCAD 2020  <br>
    
<div id="abs_ICCAD20_damo" style="text-align: justify; display: none" markdown="1">
Continuous scaling of the VLSI system leaves a great challenge on manufacturing and optical proximity correction (OPC) is widely applied in conventional design flow for manufacturability optimization. Traditional techniques conducted OPC by leveraging a lithography model and suffered from prohibitive computational overhead, and mostly focused on optimizing a single clip without addressing how to tackle the full chip. In this paper, we present DAMO, a high performance and scalable deep learning-enabled OPC system for full chip scale. It is an end-to-end mask optimization paradigm which contains a Deep Lithography Simulator (DLS) for lithography modeling and a Deep Mask Generator (DMG) for mask pattern generation. Moreover, a novel layout splitting algorithm customized for DAMO is proposed to handle the full chip OPC problem. Extensive experiments show that DAMO outperforms the state-of-the-art OPC solutions in both academia and industrial commercial toolkit.
</div>

</td>
</tr>

</table>
<h3>Layout Generation</h3>
<table class="table table-hover">

<tr id="tr-DAC23_Diff" >
<td align='right'>
1.
</td>
<td>
    DiffPattern: Layout Pattern Generation via Discrete Diffusion <br>
    <em>Zixiao&nbsp;Wang, Yunheng&nbsp;Shen, Wenqian&nbsp;Zhao, Yang&nbsp;Bai, Guojin&nbsp;Chen, Farzan&nbsp;Farnia, and Bei&nbsp;Yu</em><br>
    DAC 2023  <br>
    
</td>
</tr>

</table>



## <i class="fa fa-chevron-right"></i> Analog Layout Synthesis

<h3></h3>
<table class="table table-hover">

<tr id="tr-9712592" >
<td align='right'>
1.
</td>
<td>
    Generative-Adversarial-Network-Guided Well-Aware Placement for Analog Circuits <br>
    <em>Keren&nbsp;Zhu, Hao&nbsp;Chen, Mingjie&nbsp;Liu, Xiyuan&nbsp;Tang, Wei&nbsp;Shi, Nan&nbsp;Sun, and David&nbsp;Z.&nbsp;Pan</em><br>
    ASP-DAC 2022  <br>
    
</td>
</tr>

</table>
